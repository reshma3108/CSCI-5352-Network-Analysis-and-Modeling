{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from webweb import Web\n",
    "import networkx as nx\n",
    "import operator\n",
    "import math\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from collections import Counter\n",
    "from networkx import edge_betweenness_centrality as betweenness\n",
    "import random\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UnDirected, Weighted\n",
    "def data_undirected_weighted(df_trade,year):\n",
    "    df_trade = df_trade[df_trade['year']==year]\n",
    "    nodes_trade = np.unique(df_trade[['importer1','importer2']]).tolist()\n",
    "\n",
    "    #When both flows are >0 \n",
    "    temp1 = df_trade[(df_trade['flow1']>0) & (df_trade['flow2']>0)]\n",
    "    #Edge from importer2 - importer1\n",
    "    edges_21 = temp1[['importer2','importer1','flow1','flow2']].values.tolist()\n",
    "    \n",
    "    #When flow1>0 and flow2 either 0 or -9\n",
    "    temp2 = df_trade[(df_trade['flow1']>0) & (df_trade['flow2']==0)]\n",
    "    #Edge from importer2-> importer1\n",
    "    edges_21_single = temp2[['importer2','importer1','flow1','flow2']].values.tolist()\n",
    "    \n",
    "    #When flow1 either 0 or -9 and flow2>0\n",
    "    temp3 = df_trade[(df_trade['flow1']==0) & (df_trade['flow2']>0)]\n",
    "    #Edge from importer1-> importer2\n",
    "    edges_12_single = temp3[['importer1','importer2','flow1','flow2']].values.tolist()\n",
    "    \n",
    "    weighted_edges = []\n",
    "   \n",
    "    for edge in edges_21:\n",
    "        weight1 = (edge[2]*1000000)\n",
    "        weight2 = (edge[3]*1000000)\n",
    "        weighted_edges.append([edge[0],edge[1],(weight1+weight2)/2])\n",
    "    \n",
    "    for edge in edges_21_single:\n",
    "        weight = (edge[2]*1000000)\n",
    "        weighted_edges.append([edge[0],edge[1],weight])\n",
    "        \n",
    "    for edge in edges_12_single:\n",
    "        weight = (edge[3]*1000000)\n",
    "        weighted_edges.append([edge[0],edge[1],weight])\n",
    "       \n",
    "    edges = edges_21+edges_21_single+edges_12_single\n",
    "    \n",
    "    return nodes_trade,edges,weighted_edges\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directed, Weighted\n",
    "def data_directed_weighted(df_trade,year):\n",
    "    df_trade = df_trade[df_trade['year']==year]\n",
    "#     df_gdp = df_gdp[df_gdp['Year']==year]\n",
    "    nodes_trade = np.unique(df_trade[['importer1','importer2']]).tolist()\n",
    "\n",
    "    #When both flows are >0 \n",
    "    temp1 = df_trade[(df_trade['flow1']>0) & (df_trade['flow2']>0)]\n",
    "    #Edge from importer2-> importer1\n",
    "    edges_21 = temp1[['importer2','importer1','flow1']].values.tolist()\n",
    "    #Edge from importer1->importer2\n",
    "    edges_12 = temp1[['importer1','importer2','flow2']].values.tolist()\n",
    "    \n",
    "    #When flow1>0 and flow2 either 0 or -9\n",
    "    temp2 = df_trade[(df_trade['flow1']>0) & (df_trade['flow2']==0)]\n",
    "    #Edge from importer2-> importer1\n",
    "    edges_21_single = temp2[['importer2','importer1','flow1']].values.tolist()\n",
    "    \n",
    "    #When flow1 either 0 or -9 and flow2>0\n",
    "    temp3 = df_trade[(df_trade['flow1']==0) & (df_trade['flow2']>0)]\n",
    "    #Edge from importer1-> importer2\n",
    "    edges_12_single = temp3[['importer1','importer2','flow2']].values.tolist()\n",
    "    \n",
    "    weighted_edges = []\n",
    "   \n",
    "    for edge in edges_21:\n",
    "#         d_exp = df_gdp[df_gdp['Country'] == edge[0]]\n",
    "        weight = (edge[2]*1000000)\n",
    "        weighted_edges.append([edge[0],edge[1],weight])\n",
    "        \n",
    "    for edge in edges_12:\n",
    "#         d_exp = df_gdp[df_gdp['Country'] == edge[0]]\n",
    "        weight = (edge[2]*1000000)\n",
    "        weighted_edges.append([edge[0],edge[1],weight])\n",
    "    \n",
    "    for edge in edges_21_single:\n",
    "#         d_exp = df_gdp[df_gdp['Country'] == edge[0]]\n",
    "        weight = (edge[2]*1000000)\n",
    "        weighted_edges.append([edge[0],edge[1],weight])\n",
    "        \n",
    "    for edge in edges_12_single:\n",
    "#         d_exp = df_gdp[df_gdp['Country'] == edge[0]]\n",
    "        weight = (edge[2]*1000000)\n",
    "        weighted_edges.append([edge[0],edge[1],weight])\n",
    "       \n",
    "    edges = edges_21+edges_12+edges_21_single+edges_12_single\n",
    "    \n",
    "    labels = {}\n",
    "    labels['nodes'] = {}\n",
    "    for i in range(len(nodes)):\n",
    "        labels['nodes'][str(i)] = {'name':nodes[i]}\n",
    "        \n",
    "    return nodes,labels,edges,weighted_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_undirected(nodes,edges):\n",
    "    #Density \n",
    "    n = len(nodes)\n",
    "    total_possible_edges = n*(n-1)/2\n",
    "    density = len(edges)/total_possible_edges\n",
    "    return density\n",
    "\n",
    "def density_directed(nodes,edges):\n",
    "    #Density \n",
    "    n = len(nodes)\n",
    "    total_possible_edges = n*n\n",
    "    density = len(edges)/total_possible_edges\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graph_ud_w(nodes,weighted_edges):\n",
    "    g = nx.Graph()\n",
    "    for i in weighted_edges:\n",
    "        g.add_edge(i[0], i[1], weight=i[2]) \n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_strengths_undirected(nodes, weighted_edges):\n",
    "    node_strength = {}\n",
    "    total_weight = 0\n",
    "    for node in nodes:\n",
    "        count_strength = 0\n",
    "        for edge in weighted_edges:\n",
    "            if edge[0] == node or edge[1] == node:\n",
    "                count_strength+=edge[2]\n",
    "        total_weight+=count_strength\n",
    "        node_strength[node] = count_strength\n",
    "    return {k:v/total_weight for k,v in  node_strength.items()}\n",
    "\n",
    "def node_strengths_directed_out(nodes,weighted_edges):\n",
    "    node_strength = {}\n",
    "    total_weight = 0\n",
    "    for node in nodes:\n",
    "        count_strength = 0\n",
    "        for edge in weighted_edges:\n",
    "            if edge[0] == node:\n",
    "                count_strength+= edge[2]\n",
    "        total_weight+=count_strength\n",
    "        node_strength[node] = count_strength\n",
    "    return {k:round(v/total_weight,3) for k,v in  node_strength.items()}\n",
    "    \n",
    "    \n",
    "def node_strengths_directed_in(nodes,weighted_edges):\n",
    "    node_strength = {}\n",
    "    total_weight = 0\n",
    "    for node in nodes:\n",
    "        count_strength = 0\n",
    "        for edge in weighted_edges:\n",
    "            if edge[1] == node:\n",
    "                count_strength+=edge[2]\n",
    "        total_weight+=count_strength\n",
    "        node_strength[node] = count_strength\n",
    "    return {k:round(v/total_weight,3) for k,v in  node_strength.items()}\n",
    "\n",
    "def exports_imports_degree(nodes, edges):\n",
    "    export_rate = []\n",
    "    import_rate = []\n",
    "    degree = []\n",
    "    for node in nodes:\n",
    "        count_exp =0\n",
    "        count_imp = 0\n",
    "        count_degree = 0\n",
    "        for edge in edges:\n",
    "            if edge[0]==node:\n",
    "                count_exp+=1\n",
    "            if edge[1] ==node:\n",
    "                count_imp+=1\n",
    "            if edge[0] == node or edge[1] ==node:\n",
    "                count_degree+=1\n",
    "        export_rate.append(count_exp)\n",
    "        import_rate.append(count_imp)\n",
    "        degree.append(count_degree)\n",
    "    return export_rate,import_rate,degree\n",
    "\n",
    "def avg_degree(nodes,edges):\n",
    "    degree_avg = 0\n",
    "    for node in nodes:\n",
    "        count_degree = 0\n",
    "        for edge in edges:\n",
    "            if edge[0] == node or edge[1] ==node:\n",
    "                count_degree+=1\n",
    "        degree_avg += count_degree\n",
    "    return degree_avg/len(nodes)\n",
    "\n",
    "def avg_in_out_degree(nodes,edges):\n",
    "    degree_in =0\n",
    "    degree_out =0\n",
    "    \n",
    "    for node in nodes:\n",
    "        count_in = 0\n",
    "        count_out = 0\n",
    "        for edge in edges:\n",
    "            if edge[0]==node:\n",
    "                count_out+=1\n",
    "            if edge[1] ==node:\n",
    "                count_in+=1\n",
    "        degree_in+=count_in\n",
    "        degree_out+=count_out\n",
    "   \n",
    "    return (degree_in/len(nodes)),(degree_out/len(nodes))\n",
    "        \n",
    "        \n",
    "def cdf(freq):\n",
    "    \n",
    "    prob = {}\n",
    "    \n",
    "    for i in freq:\n",
    "        sum_ = 0\n",
    "        for j in freq:\n",
    "            if(j >= i):\n",
    "                sum_+=freq[j]\n",
    "        prob[i] = sum_\n",
    "        \n",
    "    return prob\n",
    "\n",
    "def plot_cdf(prob):\n",
    "    data = []\n",
    "    for key, value in prob.items():\n",
    "        data.append((key,value))\n",
    "    data = sorted(data, key=lambda x: x[0])\n",
    "\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for a,b in data:\n",
    "        x.append(a)\n",
    "        y.append(b)\n",
    "        \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame Trade\n",
    "df_trade = pd.read_excel('Countries_Flows.xlsx')\n",
    "df_trade['importer1'] = df_trade['importer1'].str.strip()\n",
    "df_trade['importer2'] = df_trade['importer2'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Years of data in trade data\n",
    "years = np.unique(df_trade['year']).tolist()\n",
    "years = years[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate reciprocity over the years 1920-2014\n",
    "reci = {}\n",
    "for year in years:\n",
    "    nodes,labels,edges,weighted_edges = data_directed_weighted(df_trade,year)\n",
    "    G = graph_d_w(nodes,weighted_edges)\n",
    "\n",
    "    reci[year] = nx.overall_reciprocity(G)\n",
    "\n",
    "print(reci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average degree over teh years 1920-2014\n",
    "degree_avg_dict = {}\n",
    "for year in years:\n",
    "    nodes,labels,edges,weighted_edges = data_undirected_weighted(df_trade,year)\n",
    "    degree_avg = avg_degree(nodes,edges)\n",
    "    degree_avg_dict[year] = degree_avg\n",
    "print(degree_avg_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evolution of trade network (edges), Preferential attachment like mechanism\n",
    "new_nodes_count = []\n",
    "new_edges_count = []\n",
    "new_nodes = []\n",
    "new_edges = []\n",
    "edges_from_new_nodes = []\n",
    "edges_from_old_nodes = []\n",
    "source = []\n",
    "dest = []\n",
    "\n",
    "nodes_ud_uw_prev,edges_ud_uw_prev = data_undirected_unweighted(df_trade,1920)\n",
    "print(len(edges_ud_uw_prev))\n",
    "\n",
    "for year in years[1:]:\n",
    "    nodes_ud_uw,edges_ud_uw = data_undirected_unweighted(df_trade,year)\n",
    "    nodes_diff = list(set(nodes_ud_uw)-set(nodes_ud_uw_prev))\n",
    "    \n",
    "    new_nodes_count.append(len(nodes_diff))\n",
    "    new_nodes.append(nodes_diff)\n",
    "    nodes_ud_uw_prev = nodes_ud_uw\n",
    "    \n",
    "    edges_diff = []\n",
    "    for edge in edges_ud_uw:\n",
    "        if edge not in edges_ud_uw_prev:\n",
    "            edges_diff.append(edge)\n",
    "    \n",
    "    for edge in edges_diff:\n",
    "        deg_n0 = cal_degree(edge[0],edges_ud_uw)\n",
    "        deg_n1 = cal_degree(edge[1],edges_ud_uw)\n",
    "        source.append(min(deg_n0,deg_n1))\n",
    "        dest.append(max(deg_n0,deg_n1))\n",
    "        \n",
    "    new_edges.append(edges_diff)\n",
    "    edge_new_nodes = []\n",
    "    for edge in edges_ud_uw:\n",
    "        if edge[0] in nodes_diff or edge[1] in nodes_diff:\n",
    "            edge_new_nodes.append(edge)\n",
    "\n",
    "    edges_from_new_nodes.append(len(edge_new_nodes))\n",
    "    edges_from_old_nodes.append(len(edges_diff)-len(edge_new_nodes))    \n",
    "    new_edges_count.append(len(edges_diff))\n",
    "    edges_ud_uw_prev = edges_ud_uw\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = Counter(source)\n",
    "source = dict(sorted(source.items(), key=operator.itemgetter(0),reverse=False))\n",
    "dest = Counter(dest)\n",
    "dest = dict(sorted(dest.items(), key=operator.itemgetter(0),reverse=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(source.keys()),list(source.values()),color ='g', label='Source nodes')\n",
    "plt.plot(list(dest.keys()),list(dest.values()),color ='b',label ='Destination nodes')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.savefig('PA.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"Distribution of new edges\")\n",
    "plt.plot(years[1:],new_nodes_count,'-',label='Total new nodes')\n",
    "plt.plot(years[1:],new_edges_count,'-',label='Total new edges')\n",
    "plt.plot(years[1:],edges_from_old_nodes,'-',label='Edges from existing nodes')\n",
    "plt.plot(years[1:],edges_from_new_nodes,'-',label='Edges from new nodes')\n",
    "plt.legend()\n",
    "plt.savefig('distribution_edges.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Degree Centrality UnDirected Weighted\n",
    "dict_count_ = {}\n",
    "years_ = [2005]\n",
    "for year in years_:\n",
    "    print(year)\n",
    "    nodes_ud_w,edges_ud_w,weighted_edges_ud_w = data_undirected_weighted(df_trade,2005) \n",
    "    for i in weighted_edges_ud_w:\n",
    "        i[2] = i[2]/max(map(lambda x: x[2], weighted_edges_ud_w))\n",
    "    node_strength_undirected = node_strengths_undirected(nodes_ud_w,weighted_edges_ud_w)\n",
    "    node_strength_undirected = dict(sorted(node_strength_undirected .items(), key=operator.itemgetter(1),reverse=True))\n",
    "    print(node_strength_undirected)\n",
    "    for k,v in node_strength_undirected.items():\n",
    "        if k in dict_count_:\n",
    "            dict_count_[k]+=1\n",
    "        else:\n",
    "            dict_count_[k]=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_count = dict(sorted(dict_count.items(), key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_count = dict(itertools.islice(dict_count.items(), 10))\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(list(dict_count.keys()),dict_count.values())\n",
    "ax.set_xticklabels(list(dict_count.keys()))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.title('Degree Centrality')\n",
    "plt.savefig('node_strength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eigenvector centrality UnDirected weighted\n",
    "dict_count_e_ = {}\n",
    "for year in years_:\n",
    "    if year==1942 :\n",
    "        continue\n",
    "    print(year)\n",
    "    nodes_ud_w,edges_ud_w,weighted_edges_ud_w = data_undirected_weighted(df_trade,year)\n",
    "    for i in weighted_edges_ud_w:\n",
    "        i[2] = i[2]/max(map(lambda x: x[2], weighted_edges_ud_w))\n",
    "\n",
    "    g_ud_w = graph_ud_w(nodes_ud_w,weighted_edges_ud_w)\n",
    "    eigenvector_centrality_w = {k:round(v,3) for k,v in nx.eigenvector_centrality(g_ud_w,weight='weight').items()}\n",
    "    eigenvector_centrality_w = dict( sorted(eigenvector_centrality_w.items(), key=operator.itemgetter(1),reverse=True))\n",
    "\n",
    "    print(eigenvector_centrality_w)\n",
    "    for k,v in eigenvector_centrality_w.items():\n",
    "        if k in dict_count_e_:\n",
    "            dict_count_e_[k]+=1\n",
    "        else:\n",
    "            dict_count_e_[k]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_count_e = dict(sorted(dict_count_e.items(), key=operator.itemgetter(1),reverse=True))\n",
    "dict_count_e = dict(itertools.islice(dict_count_e.items(), 10))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(list(dict_count_e.keys()),dict_count_e.values())\n",
    "ax.set_xticklabels(list(dict_count_e.keys()))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.title('Eigenvector Centrality')\n",
    "plt.savefig('eigen.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closeness Centrality UnDirected weighted\n",
    "dict_count_c_ = {}\n",
    "for year in years_:\n",
    "    print(year)\n",
    "    nodes_ud_w,edges_ud_w,weighted_edges_ud_w = data_undirected_weighted(df_trade,year)\n",
    "\n",
    "    for i in weighted_edges_ud_w:\n",
    "        i[2] = i[2]/max(map(lambda x: x[2], weighted_edges_ud_w))\n",
    "        i[2] = 1/i[2]\n",
    "\n",
    "    g_ud_w = graph_ud_w(nodes_ud_w,weighted_edges_ud_w)\n",
    "\n",
    "    closeness_centrality_ud_w = {k:v for k,v in nx.closeness_centrality(g_ud_w,distance = 'weight',wf_improved=True).items()}\n",
    "    closeness_centrality_ud_w = dict(sorted(closeness_centrality_ud_w.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    for k,v in closeness_centrality_ud_w.items():\n",
    "        if k in dict_count_c_:\n",
    "            dict_count_c_[k]+=1\n",
    "        else:\n",
    "            dict_count_c_[k]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_count_c = dict(sorted(dict_count_c.items(), key=operator.itemgetter(1),reverse=True))\n",
    "dict_count_c = dict(itertools.islice(dict_count_c.items(), 10))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(list(dict_count_c.keys()),dict_count_c.values())\n",
    "ax.set_xticklabels(list(dict_count_c.keys()))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.title('Closeness Centrality')\n",
    "plt.savefig('closeness.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
